services:
  inference:
    privileged: true
    build:
      context: ./docker/inference
      dockerfile: Dockerfile
    image: gis_inference_gpu_local
    container_name: gis_inference
    environment:
      - MODEL_ID=Qwen/Qwen2-VL-2B-Instruct
      - HF_HOME=/project/models/.hf
      - NVIDIA_VISIBLE_DEVICES=0
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./docker/inference:/app
      - ./docker_mount/project:/project
    gpus: "all"
    shm_size: "4g"
    restart: unless-stopped
    command: ["bash","-lc","pip3 install -q 'transformers==4.46.2' && python3 -m uvicorn app:app --host 0.0.0.0 --port 8081"]

  web_infer:
    restart: unless-stopped

