version: "3.9"

services:
  inference:
    privileged: true
    build:
      context: ..
      dockerfile: infra/dockerfiles/inference.gpu.Dockerfile
    image: gis_inference_gpu_local
    container_name: gis_inference
    environment:
      MODEL_ID: ${MODEL_ID:-Qwen/Qwen2-VL-2B-Instruct}
      HF_HOME: /workspace/models/.hf
      INFER_GPU: ${INFER_GPU:-0}
      CUDA_VISIBLE_DEVICES: ${INFER_GPU:-0}
      NVIDIA_VISIBLE_DEVICES: ${INFER_GPU:-0}
      NVIDIA_DRIVER_CAPABILITIES: ${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
      RESULTS_DIR: /workspace/results
      DATA_ROOT: /workspace/data
      GIS_STACK_ROOT: /workspace
    volumes:
      - ../../src/inference:/workspace/inference:ro
      - ../../data/results:/workspace/results
      - ../../data:/workspace/data
    gpus: "all"
    shm_size: "4g"
    restart: unless-stopped
    command:
      [
        "bash",
        "-lc",
        "python3 -m pip install --quiet 'transformers==4.46.2' && python3 -m uvicorn app:app --host 0.0.0.0 --port 8081"
      ]

  web_infer:
    restart: unless-stopped
